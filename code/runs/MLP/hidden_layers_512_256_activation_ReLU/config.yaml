model:
  conv_layers: [64,32]  # two convolutional layers with 32 and 64 filters respectively
  filter_size: [3, 3]  # filter size for each convolutional layer
  stride: [1, 1]  # stride for each convolutional layer
  padding: [2, 2]  # padding for each convolutional layer
  pool_type: "MaxPool"  # options: "MaxPool", "AvgPool"
  pool_size: [2, 2]  # pool size for each pooling layer
  pool_stride: [2, 2]  # pool stride for each pooling layer
  hidden_layers: [512, 256]  # two fully connected layers with 512 and 256 nodes respectively
  activation_function: "ReLU"  # options: "ReLU", "LeakyReLU", "ELU"
  use_batch_norm: True  # options: True, False
  dropout_rate: 0.1  # options: any float between 0 and 1, or None for no dropout
  regularization: "L1"  # options: "L1", "L2", None for no regularization
  l1_lambda: 0.001
  l2_lambda: 0.001
  output_size: 47
  input_size: [1,28,28]

optimizer:
  type: "Adam"  # options: "SGD", "Adam", "RMSprop", "ASGD", "AdaGrad"
  learning_rate: 0.001
  lr_scheduler: "StepLR"  # options: "StepLR", "ExponentialLR", None for no scheduler
  step_size: 10  # for StepLR
  gamma: 0.9  # for StepLR and ExponentialLR
n_epochs: 30
batch_size: 128