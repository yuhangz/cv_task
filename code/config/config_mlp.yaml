model:
  hidden_layers: [512, 256, 128]  # three hidden layers with 128, 64, and 32 nodes respectively
  activation_function: "ELU" # options: "ReLU", "LeakyReLU", "ELU"
  use_batch_norm: False   # options: True, False
  dropout_rate: 0 # options: any float between 0 and 1, or None for no dropout
  regularization: null # options: "L1", "L2", None for no regularization
  l1_lambda: 0.001
  l2_lambda: 0.001
  output_size: 47
  input_size: 784
optimizer:
  type: "RMSprop"  # options: "SGD", "Adam", "RMSprop", "ASGD", "AdaGrad"
  learning_rate: 0.001
  lr_scheduler: "StepLR"  # options: "StepLR", "ExponentialLR", None for no scheduler
  step_size: 5 # for StepLR
  gamma: 0.5 # for StepLR and ExponentialLR
n_epochs: 20
batch_size: 256
